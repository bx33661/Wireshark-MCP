"""Agentic Workflow â€” server-side orchestrated analysis tools.

These "super tools" chain multiple TSharkClient operations internally,
returning comprehensive structured reports from a single tool call.
"""

import logging

from mcp.server.fastmcp import FastMCP

from ..tshark.client import TSharkClient
from .envelope import normalize_tool_result, parse_tool_result, success_response

logger = logging.getLogger("wireshark_mcp")


# â”€â”€ Shared helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _count_lines(data: str) -> int:
    """Count non-empty data lines (excluding header)."""
    lines = [line for line in data.strip().splitlines() if line.strip()]
    return max(0, len(lines) - 1)


def _extract_data(result: str) -> str | None:
    """Parse a tool result and return the data string if successful, else None."""
    wrapped = parse_tool_result(normalize_tool_result(result))
    if wrapped["success"]:
        data = wrapped.get("data", "")
        if isinstance(data, str) and len(data.strip()) > 10:
            return data
    return None


async def _safe_run(coro, default=None):
    """Run a coroutine, returning default on any exception."""
    try:
        return await coro
    except Exception as e:
        logger.debug("Safe run caught exception: %s", e)
        return default


# â”€â”€ Security Audit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


async def _run_security_audit(client: TSharkClient, pcap_file: str) -> str:
    """Execute comprehensive security audit pipeline."""

    report: list[str] = []
    findings: list[str] = []
    risk_score = 0  # 0-100, higher = worse

    report.append("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    report.append("â•‘           SECURITY AUDIT REPORT                     â•‘")
    report.append("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

    # â”€â”€ Phase 1: File & Protocol Overview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    file_info_raw = await _safe_run(client.get_file_info(pcap_file), "")
    file_info = _extract_data(file_info_raw) if file_info_raw else None

    phs_raw = await _safe_run(client.get_protocol_stats(pcap_file), "")
    phs_data = _extract_data(phs_raw) if phs_raw else None

    report.append("â”Œâ”€â”€â”€ 1. File Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    if file_info:
        # Take first 10 lines of capinfos output
        for line in file_info.strip().splitlines()[:10]:
            report.append(f"â”‚  {line}")
    else:
        report.append("â”‚  âš ï¸  Could not read file info")
    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # Detect protocols present
    detected_protocols: set[str] = set()
    if phs_data:
        import re

        for line in phs_data.splitlines():
            match = re.match(r"^\s*(\w[\w.-]*)\s+frames:", line)
            if match:
                detected_protocols.add(match.group(1).lower())

    report.append("â”Œâ”€â”€â”€ 2. Protocol Overview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    if detected_protocols:
        report.append(f"â”‚  Detected: {', '.join(sorted(detected_protocols))}")
    else:
        report.append("â”‚  No protocol hierarchy available")
    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 2: Threat Intelligence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    report.append("â”Œâ”€â”€â”€ 3. Threat Intelligence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    # Extract unique IPs
    unique_ips: set[str] = set()
    ips_raw = await _safe_run(client.extract_fields(pcap_file, ["ip.src", "ip.dst"], limit=10000), "")
    ips_data = _extract_data(ips_raw) if ips_raw else None
    if ips_data:
        for line in ips_data.splitlines()[1:]:
            for val in line.split("\t"):
                val = val.strip().strip('"')
                if val and not val.startswith("["):
                    unique_ips.add(val)

    report.append(f"â”‚  Unique IPs found: {len(unique_ips)}")

    # Check against URLhaus
    malicious_ips: list[str] = []
    try:
        from .security import _get_threat_data

        threat_feed = await _get_threat_data()
        malicious_ips = [ip for ip in unique_ips if ip in threat_feed]

        if malicious_ips:
            risk_score += 40
            findings.append(f"ğŸ”´ {len(malicious_ips)} IP(s) found in URLhaus threat feed")
            report.append(f"â”‚  ğŸ”´ MALICIOUS IPs: {len(malicious_ips)}")
            for ip in malicious_ips[:10]:
                report.append(f"â”‚     â€¢ {ip}")
            if len(malicious_ips) > 10:
                report.append(f"â”‚     ... and {len(malicious_ips) - 10} more")
        else:
            report.append("â”‚  ğŸŸ¢ No IPs matched known threat feeds")
    except Exception as e:
        report.append(f"â”‚  âš ï¸  Threat feed unavailable: {e}")

    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 3: Credential Exposure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    report.append("â”Œâ”€â”€â”€ 4. Credential Exposure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    cred_found = False

    # HTTP Basic Auth
    http_auth_raw = await _safe_run(
        client.extract_fields(pcap_file, ["http.authbasic"], "http.authbasic", limit=50), ""
    )
    http_auth = _extract_data(http_auth_raw) if http_auth_raw else None
    if http_auth and len(http_auth.strip()) > 20:
        cred_found = True
        risk_score += 25
        findings.append("ğŸ”´ HTTP Basic Auth credentials found in cleartext")
        lines = http_auth.strip().splitlines()
        report.append(f"â”‚  ğŸ”´ HTTP Basic Auth: {len(lines) - 1} instance(s)")

    # FTP passwords
    ftp_raw = await _safe_run(
        client.extract_fields(pcap_file, ["ftp.request.arg"], "ftp.request.command == PASS", limit=50), ""
    )
    ftp_data = _extract_data(ftp_raw) if ftp_raw else None
    if ftp_data and len(ftp_data.strip()) > 20:
        cred_found = True
        risk_score += 25
        findings.append("ğŸ”´ FTP passwords found in cleartext")
        lines = ftp_data.strip().splitlines()
        report.append(f"â”‚  ğŸ”´ FTP Passwords: {len(lines) - 1} instance(s)")

    if not cred_found:
        report.append("â”‚  ğŸŸ¢ No plaintext credentials detected")

    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 4: Port Scanning Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    report.append("â”Œâ”€â”€â”€ 5. Port Scanning Activity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    syn_raw = await _safe_run(
        client.extract_fields(
            pcap_file,
            ["ip.src", "tcp.dstport"],
            display_filter="tcp.flags.syn == 1 and tcp.flags.ack == 0",
            limit=10000,
        ),
        "",
    )
    syn_data = _extract_data(syn_raw) if syn_raw else None

    if syn_data:
        src_to_ports: dict[str, set[str]] = {}
        for line in syn_data.splitlines()[1:]:
            parts = line.split("\t")
            if len(parts) >= 2:
                src = parts[0].strip().strip('"')
                port = parts[1].strip().strip('"')
                if src and port:
                    src_to_ports.setdefault(src, set()).add(port)

        scanners = {s: p for s, p in src_to_ports.items() if len(p) >= 15}
        if scanners:
            risk_score += 20
            findings.append(f"ğŸ”´ {len(scanners)} port scanner(s) detected")
            for src, ports in sorted(scanners.items(), key=lambda x: len(x[1]), reverse=True)[:5]:
                report.append(f"â”‚  ğŸ”´ {src} â†’ {len(ports)} unique ports")
        else:
            report.append(f"â”‚  ğŸŸ¢ No port scanning detected (SYN sources: {len(src_to_ports)})")
    else:
        report.append("â”‚  ğŸŸ¢ No SYN-only packets found")

    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 5: DNS Anomalies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    report.append("â”Œâ”€â”€â”€ 6. DNS Anomaly Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    if "dns" in detected_protocols:
        dns_raw = await _safe_run(
            client.extract_fields(pcap_file, ["dns.qry.name", "dns.qry.type"], display_filter="dns", limit=5000), ""
        )
        dns_data = _extract_data(dns_raw) if dns_raw else None

        if dns_data:
            long_queries = 0
            txt_queries = 0
            subdomains_per_base: dict[str, set[str]] = {}
            total_dns = 0

            for line in dns_data.splitlines()[1:]:
                parts = line.split("\t")
                if len(parts) >= 2:
                    qname = parts[0].strip().strip('"')
                    qtype = parts[1].strip().strip('"')
                    if not qname:
                        continue
                    total_dns += 1
                    if len(qname) > 50:
                        long_queries += 1
                    if qtype in ("16", "TXT"):
                        txt_queries += 1
                    domain_parts = qname.split(".")
                    if len(domain_parts) >= 3:
                        base = ".".join(domain_parts[-2:])
                        sub = ".".join(domain_parts[:-2])
                        subdomains_per_base.setdefault(base, set()).add(sub)

            report.append(f"â”‚  Total DNS queries: {total_dns}")

            dns_indicators = 0
            if long_queries > 5:
                dns_indicators += 1
                report.append(f"â”‚  ğŸ”´ Long queries (>50 chars): {long_queries}")
            if txt_queries > 10:
                dns_indicators += 1
                report.append(f"â”‚  ğŸŸ  TXT record queries: {txt_queries}")
            suspicious_bases = {b: s for b, s in subdomains_per_base.items() if len(s) > 20}
            if suspicious_bases:
                dns_indicators += 1
                for base, subs in sorted(suspicious_bases.items(), key=lambda x: len(x[1]), reverse=True)[:3]:
                    report.append(f"â”‚  ğŸ”´ {base}: {len(subs)} unique subdomains")

            if dns_indicators >= 2:
                risk_score += 25
                findings.append("ğŸ”´ DNS tunneling indicators detected")
            elif dns_indicators == 1:
                findings.append("ğŸŸ¡ Minor DNS anomalies detected")
            else:
                report.append("â”‚  ğŸŸ¢ No DNS tunneling indicators")
        else:
            report.append("â”‚  No DNS data to analyze")
    else:
        report.append("â”‚  â„¹ï¸  No DNS traffic in capture")

    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 6: Cleartext Protocol Usage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    report.append("â”Œâ”€â”€â”€ 7. Cleartext Protocol Usage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    cleartext_checks = [
        ("FTP", "ftp"),
        ("Telnet", "telnet"),
        ("HTTP (unencrypted)", "http"),
        ("SMTP", "smtp"),
        ("POP3", "pop"),
        ("IMAP", "imap"),
    ]

    cleartext_found = []
    for name, dfilter in cleartext_checks:
        if dfilter in detected_protocols or dfilter == "http":
            check_raw = await _safe_run(client.get_packet_list(pcap_file, limit=1, display_filter=dfilter), "")
            check_data = _extract_data(check_raw) if check_raw else None
            if check_data and _count_lines(check_data) > 0:
                cleartext_found.append(name)
                report.append(f"â”‚  ğŸŸ  {name}: DETECTED")

    if cleartext_found:
        risk_score += 10
        findings.append(f"ğŸŸ  Cleartext protocols in use: {', '.join(cleartext_found)}")

    if not cleartext_found:
        report.append("â”‚  ğŸŸ¢ No cleartext protocols detected")

    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 7: Expert Info (Protocol Anomalies) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    report.append("â”Œâ”€â”€â”€ 8. Protocol Anomalies (Expert Info) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    expert_raw = await _safe_run(client.get_expert_info(pcap_file), "")
    expert_data = _extract_data(expert_raw) if expert_raw else None
    if expert_data:
        if "Malformed" in expert_data:
            risk_score += 10
            findings.append("ğŸŸ  Malformed packets detected")
            report.append("â”‚  ğŸ”´ Malformed packets detected")
        if "Reassembly error" in expert_data:
            findings.append("ğŸŸ¡ Reassembly errors found")
            report.append("â”‚  ğŸŸ  Reassembly errors found")
        if "Retransmission" in expert_data:
            report.append("â”‚  ğŸŸ¡ TCP retransmissions present")
        if not any(w in expert_data for w in ["Malformed", "Reassembly", "Retransmission"]):
            report.append("â”‚  ğŸŸ¢ No notable protocol anomalies")
    else:
        report.append("â”‚  No expert info available")

    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Final Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    risk_score = min(risk_score, 100)
    if risk_score >= 60:
        risk_level = "ğŸ”´ CRITICAL"
    elif risk_score >= 40:
        risk_level = "ğŸŸ  HIGH"
    elif risk_score >= 20:
        risk_level = "ğŸŸ¡ MEDIUM"
    else:
        risk_level = "ğŸŸ¢ LOW"

    report.append("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    report.append(f"â•‘  RISK LEVEL: {risk_level:<40}â•‘")
    report.append(f"â•‘  RISK SCORE: {risk_score}/100{' ' * 36}â•‘")
    report.append(f"â•‘  FINDINGS:   {len(findings)} issue(s){' ' * 33}â•‘")
    report.append("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

    if findings:
        report.append("â”€â”€ Findings Summary â”€â”€")
        for i, f in enumerate(findings, 1):
            report.append(f"  {i}. {f}")

    report.append("\nâ”€â”€ Recommendations â”€â”€")
    if risk_score >= 40:
        report.append("  â€¢ Investigate flagged malicious IPs and credential exposure immediately")
        report.append("  â€¢ Use wireshark_follow_stream to examine suspicious connections")
        report.append("  â€¢ Consider blocking identified scanner/attacker IPs")
    if cleartext_found:
        report.append("  â€¢ Migrate cleartext protocols to encrypted alternatives (HTTPS, SFTP, etc.)")
    if risk_score < 20:
        report.append("  â€¢ No critical issues found â€” routine monitoring recommended")

    return success_response("\n".join(report))


# â”€â”€ Quick Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


async def _run_quick_analysis(client: TSharkClient, pcap_file: str) -> str:
    """Execute quick traffic analysis pipeline."""

    report: list[str] = []

    report.append("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    report.append("â•‘           QUICK ANALYSIS REPORT                     â•‘")
    report.append("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

    # â”€â”€ Phase 1: File Info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    file_info_raw = await _safe_run(client.get_file_info(pcap_file), "")
    file_info = _extract_data(file_info_raw) if file_info_raw else None

    report.append("â”Œâ”€â”€â”€ 1. Capture File Info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    if file_info:
        for line in file_info.strip().splitlines()[:12]:
            report.append(f"â”‚  {line}")
    else:
        report.append("â”‚  âš ï¸  Could not read file info")
    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 2: Protocol Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    phs_raw = await _safe_run(client.get_protocol_stats(pcap_file), "")
    phs_data = _extract_data(phs_raw) if phs_raw else None

    report.append("â”Œâ”€â”€â”€ 2. Protocol Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    if phs_data:
        for line in phs_data.strip().splitlines()[:20]:
            report.append(f"â”‚  {line}")
    else:
        report.append("â”‚  No protocol data available")
    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 3: Top Talkers (Endpoints) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    endpoints_raw = await _safe_run(client.get_endpoints(pcap_file, "ip"), "")
    endpoints_data = _extract_data(endpoints_raw) if endpoints_raw else None

    report.append("â”Œâ”€â”€â”€ 3. Top Talkers (IP Endpoints) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    if endpoints_data:
        for line in endpoints_data.strip().splitlines()[:15]:
            report.append(f"â”‚  {line}")
    else:
        report.append("â”‚  No endpoint data available")
    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 4: Top Conversations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    conv_raw = await _safe_run(client.get_conversations(pcap_file, "tcp"), "")
    conv_data = _extract_data(conv_raw) if conv_raw else None

    report.append("â”Œâ”€â”€â”€ 4. Top Conversations (TCP) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    if conv_data:
        for line in conv_data.strip().splitlines()[:15]:
            report.append(f"â”‚  {line}")
    else:
        report.append("â”‚  No conversation data available")
    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 5: Key Hostnames â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    report.append("â”Œâ”€â”€â”€ 5. Key Hostnames â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    # HTTP hosts
    http_hosts_raw = await _safe_run(client.extract_fields(pcap_file, ["http.host"], "http.request", limit=500), "")
    http_hosts_data = _extract_data(http_hosts_raw) if http_hosts_raw else None

    http_hosts: dict[str, int] = {}
    if http_hosts_data:
        for line in http_hosts_data.splitlines()[1:]:
            host = line.strip().strip('"')
            if host:
                http_hosts[host] = http_hosts.get(host, 0) + 1

    if http_hosts:
        report.append("â”‚  HTTP Hosts:")
        for host, count in sorted(http_hosts.items(), key=lambda x: x[1], reverse=True)[:10]:
            report.append(f"â”‚    {host} ({count} requests)")

    # DNS top domains
    dns_raw = await _safe_run(
        client.extract_fields(pcap_file, ["dns.qry.name"], "dns.flags.response == 0", limit=500), ""
    )
    dns_data = _extract_data(dns_raw) if dns_raw else None

    dns_domains: dict[str, int] = {}
    if dns_data:
        for line in dns_data.splitlines()[1:]:
            domain = line.strip().strip('"')
            if domain:
                dns_domains[domain] = dns_domains.get(domain, 0) + 1

    if dns_domains:
        report.append("â”‚  DNS Queries (top domains):")
        for domain, count in sorted(dns_domains.items(), key=lambda x: x[1], reverse=True)[:10]:
            report.append(f"â”‚    {domain} ({count} queries)")

    if not http_hosts and not dns_domains:
        report.append("â”‚  No HTTP/DNS hostname data found")

    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Phase 6: Anomaly Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    expert_raw = await _safe_run(client.get_expert_info(pcap_file), "")
    expert_data = _extract_data(expert_raw) if expert_raw else None

    report.append("â”Œâ”€â”€â”€ 6. Anomaly Summary (Expert Info) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    if expert_data:
        anomaly_keywords = {
            "Retransmission": "ğŸŸ¡",
            "Duplicate ACK": "ğŸŸ¡",
            "Out-of-Order": "ğŸŸ ",
            "Malformed": "ğŸ”´",
            "Reassembly error": "ğŸŸ ",
            "Zero window": "ğŸŸ¡",
        }
        found_any = False
        for keyword, icon in anomaly_keywords.items():
            if keyword in expert_data:
                report.append(f"â”‚  {icon} {keyword} detected")
                found_any = True
        if not found_any:
            report.append("â”‚  ğŸŸ¢ No notable anomalies")
    else:
        report.append("â”‚  No expert info available")
    report.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")

    # â”€â”€ Suggested Next Steps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    report.append("â”€â”€ Suggested Next Steps â”€â”€")
    report.append("  â€¢ wireshark_get_packet_list â€” browse specific traffic with display filters")
    report.append("  â€¢ wireshark_follow_stream â€” reconstruct TCP/HTTP conversations")
    report.append("  â€¢ wireshark_security_audit â€” run full security audit on this file")
    if http_hosts:
        report.append("  â€¢ wireshark_extract_http_requests â€” detailed HTTP request analysis")
    if dns_domains:
        report.append("  â€¢ wireshark_extract_dns_queries â€” detailed DNS query analysis")

    return success_response("\n".join(report))


# â”€â”€ Registration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def register_agent_tools(mcp: FastMCP, client: TSharkClient) -> None:
    """Register agentic workflow super tools."""

    @mcp.tool()
    async def wireshark_security_audit(pcap_file: str) -> str:
        """
        [Agent] One-call comprehensive security audit.

        Automatically runs 8 analysis phases internally and returns a structured
        security report with risk scoring. No manual tool-chaining needed.

        Phases: File summary â†’ Protocol overview â†’ Threat intelligence (URLhaus) â†’
        Credential exposure â†’ Port scan detection â†’ DNS anomaly detection â†’
        Cleartext protocol usage â†’ Protocol anomalies (Expert Info)

        Args:
            pcap_file: Path to capture file

        Returns:
            Complete security audit report with risk level, findings, and recommendations.

        Example:
            wireshark_security_audit("suspicious_traffic.pcap")
        """
        return await _run_security_audit(client, pcap_file)

    @mcp.tool()
    async def wireshark_quick_analysis(pcap_file: str) -> str:
        """
        [Agent] One-call traffic overview and analysis.

        Automatically gathers file info, protocol distribution, top talkers,
        conversations, hostnames, and anomalies into a single comprehensive report.

        Phases: File info â†’ Protocol distribution â†’ Top talkers â†’ Top conversations â†’
        Key hostnames (HTTP + DNS) â†’ Anomaly summary (Expert Info)

        Args:
            pcap_file: Path to capture file

        Returns:
            Complete traffic analysis report with suggested next steps.

        Example:
            wireshark_quick_analysis("capture.pcap")
        """
        return await _run_quick_analysis(client, pcap_file)
